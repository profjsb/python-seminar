{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".input_prompt, .CodeMirror-lines, .output_area\n",
       "{\n",
       "  font-family: Consolas;\n",
       "  font-size: 120%;\n",
       "  }\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../00_AdvancedPythonConcepts/talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PyTables and HDF5\n",
    "-----------------------\n",
    "UC Berkeley Python class (AY250; 2013-2016)\n",
    "\n",
    "\n",
    "*\"PyTables presents a database-like approach to data storage, providing features like indexing and fast “in-kernel” queries on dataset contents. It also has a custom system to represent data types.\" -- http://docs.h5py.org/en/latest/faq.html#what-s-the-difference-between-h5py-and-pytables*\n",
    "\n",
    "First we'll open a new HDF5 for writing (note: the \"w\" implies we will overwrite the file we have on disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbloom/anaconda/envs/seminar/lib/python3.5/site-packages/ipykernel/__main__.py:3: DeprecationWarning: openFile() is pending deprecation, use open_file() instead. You may use the pt2to3 tool to update your source code.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "File(filename=spam.h5, title='PyTables/HDF5 test file', mode='w', root_uep='/', filters=Filters(complevel=0, shuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) 'PyTables/HDF5 test file'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tables import *\n",
    "h5file = open_file(\"spam.h5\",mode = \"w\", title = \"PyTables/HDF5 test file\")\n",
    "h5file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters sets the protocols for the way all data will be treated in the file. `fletcher32 = True`, for instance will enforce checksums (slower, but more stable data), `complevel` is the compression level, etc.\n",
    "\n",
    "Now, let's create a 100$\\times$100 random image with `create_array` and associate it with a group called \"Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbloom/anaconda/envs/seminar/lib/python3.5/site-packages/ipykernel/__main__.py:2: DeprecationWarning: createArray() is pending deprecation, use create_array() instead. You may use the pt2to3 tool to update your source code.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "/Datasets/dataset1 (Array(100, 100)) 'Test data set #1'\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = h5file.create_group(h5file.root, \"Datasets\", \"Test data sets\")\n",
    "h5file.create_array(datasets, 'dataset1', np.random.random((100,100)), \"Test data set #1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a complex object which we'll call a \"Particle\" that has the properties like name, atomic number, mass, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Particle(IsDescription):\n",
    "    name        = StringCol(16, pos=1) # 16-character String\n",
    "    atomic_num  = IntCol(pos=2)        # integer\n",
    "    mass        = FloatCol(pos=3)      # double (double-precision)\n",
    "    pressure    = Float32Col(shape=(2,3))\n",
    "table1 = h5file.create_table(datasets, \"particles\", Particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Datasets/particles.row (Row), pointing to row #0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = table1.row\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some data into the first particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'oxygen', 8, 15.9994, [[1.0, 2.0, 3.0], [-1.0, 1.0, 3.0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[\"name\"] = \"oxygen\"\n",
    "row[\"atomic_num\"] = 8\n",
    "row[\"mass\"] = 15.9994\n",
    "row[\"pressure\"] = [[1,2,3],[-1,1,3]]\n",
    "row.append() ; table1.flush()\n",
    "h5file.root.Datasets.particles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, unlike numpy arrays, we can append new data. So this seems more like a DB in this respect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'bezerkilum', 150, 360.0, [[1.0, 2.0, 3.0], [1.0, 0.0, 3.0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = table1.row\n",
    "row[\"name\"] = \"bezerkilum\"\n",
    "row[\"atomic_num\"] = 150\n",
    "row[\"mass\"] = 360.0\n",
    "row[\"pressure\"] = [[1,2,3],[1,0,3]]\n",
    "row.append() ; table1.flush()\n",
    "h5file.root.Datasets.particles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oxygen']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row['name'].decode() for row in table1.where('(atomic_num > 5) & (mass < 100.0)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oxygen\n",
      "bezerkilum\n"
     ]
    }
   ],
   "source": [
    "for row in table1:\n",
    "    print(row[\"name\"].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5py\n",
    "\n",
    "Groups work like dictionaries, and datasets work like NumPy arrays\n",
    "\n",
    "http://docs.h5py.org/en/latest/quick.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"spam-h5py.h5\" (mode r+)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "!rm spam-h5py.h5\n",
    "h5file = h5py.File(\"spam-h5py.h5\",mode = \"w\", title = \"h5py/HDF5 test file\")\n",
    "h5file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In h5py, \"Datasets are very similar to NumPy arrays. They are homogenous collections of data elements, with an immutable datatype and (hyper)rectangular shape. Unlike NumPy arrays, they support a variety of transparent storage features such as compression, error-detection, and chunked  I/O.\" -- http://docs.h5py.org/en/latest/high/dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets = h5file.create_group(\"Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"dataset2\": shape (100, 100), type \"<f8\">"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.create_dataset('Datasets/dataset1', data=np.random.random((100,100)))\n",
    "datasets.create_dataset('Datasets/dataset2', data=np.random.random((100,100)),\n",
    "                        compression=\"gzip\", compression_opts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = datasets.get('Datasets/dataset2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97794214,  0.11794942,  0.39368585, ...,  0.7658321 ,\n",
       "         0.78288034,  0.9464316 ],\n",
       "       [ 0.76573763,  0.8718638 ,  0.7027056 , ...,  0.01710255,\n",
       "         0.92814481,  0.80044144],\n",
       "       [ 0.33383122,  0.53455644,  0.91913964, ...,  0.57837372,\n",
       "         0.56180651,  0.10364729],\n",
       "       ..., \n",
       "       [ 0.23370288,  0.43693144,  0.73115798, ...,  0.93510635,\n",
       "         0.67461141,  0.38052106],\n",
       "       [ 0.30162771,  0.62406416,  0.83488421, ...,  0.14604748,\n",
       "         0.83666988,  0.26251197],\n",
       "       [ 0.14676648,  0.43856595,  0.16412232, ...,  0.55433556,\n",
       "         0.70228834,  0.0908137 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53455644,  0.55951379,  0.27516592],\n",
       "       [ 0.0754908 ,  0.62502142,  0.9400895 ],\n",
       "       [ 0.64286464,  0.44354353,  0.2552696 ],\n",
       "       [ 0.93754221,  0.16648524,  0.9980154 ],\n",
       "       [ 0.40565599,  0.30440593,  0.13540566],\n",
       "       [ 0.64642334,  0.89577348,  0.71847996],\n",
       "       [ 0.81442915,  0.47496836,  0.80107197],\n",
       "       [ 0.18471405,  0.780301  ,  0.21541965]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2:10,1:9:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = [(\"name\",\"S16\"),(\"atomic_num\",\"i4\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Particle\": shape (100, 1), type \"|V20\">"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.create_dataset(\"Particle\", shape=(100,1), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdata = datasets.get(\"Particle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdata[0] = (\"oxygen\",8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(b'oxygen', 8)]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"spam-h5py.h5\",mode = \"r\") as f:\n",
    "    pdata = f.get(\"Datasets/Particle\")\n",
    "    print(pdata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
